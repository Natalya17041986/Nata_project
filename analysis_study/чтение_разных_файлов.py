import pandas as pd 
# Импорт библиотеки pandas — при выполнении последовательно всех примеров ниже, импорт библиотеки pandas выполняется один раз

countries_data = pd.read_csv('data/countries.csv', sep=';') 
# Загружаем данные из файла в переменную, создавая объект DataFrame

countries_data.to_csv('data/countries.txt', index=False, sep=' ') 
# Выгружаем данные из DataFrame в CSV-файл и сохраняем файл в папке data

## ФАЙЛЫ TXT

# Считаем данные из файла countries.txt в переменную txt_df  (объект DataFrame), 
# применив функцию read_table() с параметрами sep=' '  и  index_col=['country']
# (так мы избавимся от столбца с индексом и присвоим названия строкам, используя данные одного из столбцов). Выводим на экран полученный результат:

txt_df = pd.read_table('data/countries.txt', sep=' ', index_col=['country'])
# Загружаем данные из файла в переменную, создавая объект DataFrame

print(txt_df) 
# Выводим содержимое DataFrame на экран

# Например, если при считывании данных из ранее сохранённого в папке data файла melb_data_ps.csv 
# указать значение параметра header=None, то первая строка исходного файла не будет восприниматься как с
# трока заголовка и будет отнесена к области данных DataFrame:

melb_data = pd.read_csv('data/melb_data_ps.csv', header=None) 
# Загружаем данные из файла в переменную, создавая объект DataFrame

print(melb_data) 
# Выводим содержимое DataFrame на экран
import urllib.request
import chardet

# Считываем данные из файла с неизвестной кодировкой в переменную, создавая объект DataFrame


# Приведённый ниже код поможет нам определить используемую кодировку в файле, степень достоверности, используемый язык.

from chardet.universaldetector import UniversalDetector # Импортируем субмодуль chardet.universaldetector
detector = UniversalDetector()
with open('data/ErrorEnCoding.csv', 'rb') as fh:
    for line in fh:
        detector.feed(line)
        if detector.done:
            break
detector.close()
print(detector.result)

#С достоверностью примерно 84 % тип используемой в файле кодировки — koi8-r. 
# Повторим считывание файла, используя полученные данные.

# ДОПОЛНИТЕЛЬНО
# При открытии файла использовалась конструкция with ... as ... (с англ. «с... как...»). 
# Эта конструкция применяется для гарантии того, что критические функции и методы (в данном случае метод .close() 
# закрывает открытый ранее файл) будут выполнены в любом случае.

 # with open('path/filename') as f: # Открываем файл и связываем его с объектом "f"
    # Работа с файлом...
    # ...не забываем про отступ...
    # ...
# Нет отступа = работа с файлом закончена, файл filename закрыт
# Как упоминалось ранее, здесь конструкция with ... as ... гарантирует закрытие файла filename, связанного с объектом f.

 # Создаем DataFrame из файла, явно указав кодировку символов, и выводим его содержимое на экран
data=pd.read_csv('data/ErrorEnCoding.csv', encoding='koi8-r', header=None )
print(data)

# Ранее вы уже считывали данные из файла melb_data.csv, который находится в свободном доступе в интернете, 
# используя функцию read_csv(). Попробуем использовать функцию read_table(), указав в качестве разделителя данных 
# запятую — ','.

data = pd.read_table('https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv', sep=',')
print(data)

# Как видим, функция read_table() сработала и с CSV-файлом — достаточно было указать, какой разделитель используется.

# Механизм, используемый в функции read_csv(), позволяет проводить чтение текстового файла из архива, 
# не распаковывая его. Функция read_csv() сама распознает архив и извлекает из него данные 
# (работает практически со всеми zip-архивами). Есть ограничение — файл в zip-архиве должен быть один 
# (если файлов в архиве несколько, то можно разархивировать файлы и работать с каждым вне архива. 
# Подробнее об этом поговорим в юните Итоги).
# Ранее вы работали с датасетом students_performance.csv, упакованным в архив. 
# Для работы с файлом вы предварительно проводили распаковку архива. Попробуем начать работу с файлом, 
# не распаковывая его.

data = pd.read_csv('data/students_performance.zip')
print(data)

# В функции to_csv() предусмотрен механизм, позволяющий проводить упаковку CSV-файлов в zip-архив. 
# Проделаем обратную операцию — данные из DataFrame data запишем в CSV-файл, упакуем полученный файл в 
# zip-архив «на лету» и сохраним полученный архив в папке data, выполнив следующий код:

compression_opts = dict(method='zip', archive_name='out.csv') # Определяем параметры архивирования — метод сжатия, имя файл в архиве
data.to_csv('data/out.zip', index=False, compression=compression_opts)

# В ходе выполнения кода содержимое DataFrame сохранено в файле out.csv, файл упакован в архив out.zip, 
# а архив записан в каталог data.

## ФАЙЛЫ EXCEL

# Файл Excel называется рабочей книгой. Каждая книга может хранить некоторое количество листов. 
# Лист, просматриваемый пользователем в данный момент, называется активным. Лист состоит из столбцов 
# (адресуемых, как правило, с помощью букв, начиная с A) и строк (адресуемых с помощью цифр, начиная с 1).
# Лист может содержать данные в виде таблиц, формул, изображений, графиков и информации о форматировании.
# В этом разделе будут рассмотрены функции read_excel() и to_excel() из библиотеки pandas. 
# С их помощью можно считывать данные из файлов Excel и выполнять запись в них. С помощью различных параметров 
# есть возможность менять поведение функций, создавая нужные файлы, а не просто копируя содержимое из объекта DataFrame.

# Попробуем прочитать наш файл-пример. Для этого передадим в read_excel() путь к нему. 
# Чтобы его открыть и сохранить данные в переменную grades, необходимо выполнить следующий код:

grades = pd.read_excel('data/grades.xlsx')
print(grades.head())

# Если файл находится в открытом доступе по ссылке (например, на Google Диске или GitHub), 
# его можно прочитать и из интернета — для этого достаточно в функции read_excel() вместо пути до файла указать 
# ссылку на файл. Например:

data = pd.read_excel('https://github.com/asaydn/test/raw/master/january.xlsx')
print(data)

# Как упоминалось выше, один Excel-файл может включать в себя несколько листов, которые отображаются 
# в разных вкладках (англ. sheet, рус. лист). Например, в нашем файле два листа — Maths и ML.
# По умолчанию в DataFrame читается информация из первого листа, однако read_excel()  позволяет выбрать, 
# из какого именно листа загружать данные. Сделать это можно с помощью параметра sheet_name (рус. имя_листа). 
# Например, чтобы прочесть данные из второго листа (ML) файла, выполним код:

grades = pd.read_excel('data/grades.xlsx', sheet_name='ML')
print(grades.head())

# После обработки данных (очистка, создание новых признаков и т. д.) методами и функциями pandas мы сталкиваемся 
# с обратной задачей — сохранить данные из DataFrame в Excel-файл.
# Для этого в pandas есть функция to_excel() (рус. в_Excel), принцип работы которой очень схож с функцией to_csv():

grades.to_excel('data/grades_new.xlsx') # Сохраняем данные из DataFrame grades в файл grades_new.xlsx в папке data

# В этом случае будет создан один лист с именем по умолчанию "Sheet1". Также мы сохраним и индекс — в данных 
# будет находиться лишний столбец. Чтобы создать лист с определённым именем (например, Example) и не сохранять индекс,
# в метод  to_excel() необходимо передать параметры sheet_name='Example' и index=False:

grades.to_excel('data/grades_new.xlsx', sheet_name='Example', index=False) 
# Сохраняем данные из DataFrame grades в файл grades_new.xlsx (на листе 'Example') в папке data

ratings = pd.read_excel('data/ratings+movies.xlsx')
print(ratings.head())

# Считайте данные из двух листов файла ratings+movies.xlsx в разные DataFrame, объедините в один, 
# запишите данные из полученного DataFrame в файл. Сколько строк (включая строку заголовков) в результирующем файле?

ratings = pd.read_excel('data/ratings+movies.xlsx', sheet_name = 'ratings')         
movies = pd.read_excel('data/ratings+movies.xlsx', sheet_name = 'movies')         
joined = ratings.merge(movies, on='movieId', how='left')         
joined.to_excel('joined.xlsx', sheet_name ='JOINED', index=False)

print(joined)

## ФАЙЛЫ JSON

